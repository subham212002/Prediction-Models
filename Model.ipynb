{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85845733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\kiit\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kiit\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0380055a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_train =pd.read_csv('train_csv.csv' )\n",
    "print(loan_train.shape) # (614, 13)\n",
    "loan_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab96f9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit_History      50\n",
       "Self_Employed       32\n",
       "LoanAmount          22\n",
       "Dependents          15\n",
       "Loan_Amount_Term    14\n",
       "Gender              13\n",
       "Married              3\n",
       "Loan_ID              0\n",
       "Education            0\n",
       "ApplicantIncome      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_null=loan_train.isnull().sum().sort_values(ascending=False)\n",
    "total_null.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb7afe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "loan_train['Gender'] = loan_train ['Gender'].fillna( loan_train['Gender'].dropna ().mode().values[0])\n",
    "loan_train['Married'] = loan_train['Married'].fillna( loan_train['Married'].dropna ().mode().values[0])\n",
    "loan_train['Dependents'] = loan_train['Dependents'].fillna(loan_train['Dependents'].dropna ().mode().values[0])\n",
    "loan_train['Self Employed'] = loan_train[ 'Self_Employed'].fillna(loan_train['Self_Employed'].dropna().mode().values [0] )\n",
    "loan_train['LoanAmount'] = loan_train['LoanAmount'].fillna(loan_train ['LoanAmount'].dropna().mean())\n",
    "loan_train['Loan_Amount_Term'] = loan_train[ 'Loan_Amount_Term'].fillna(loan_train['Loan_Amount_Term'].dropna ().mode().values [0])\n",
    "loan_train['Credit_History'] = loan_train [ 'Credit_History'].fillna(loan_train['Credit_History'].dropna().mode().values [0])\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b4ad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             614 non-null    object \n",
      " 2   Married            614 non-null    object \n",
      " 3   Dependents         614 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         614 non-null    float64\n",
      " 9   Loan_Amount_Term   614 non-null    float64\n",
      " 10  Credit_History     614 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      " 13  Self Employed      614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(9)\n",
      "memory usage: 67.3+ KB\n"
     ]
    }
   ],
   "source": [
    "loan_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f67c875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Male', 'Female'}\n",
      "{'1', '3+', '0', '2'}\n",
      "{'Yes', 'No'}\n",
      "{'Not Graduate', 'Graduate'}\n",
      "{nan, 'Yes', 'No'}\n",
      "{'N', 'Y'}\n",
      "{'Rural', 'Urban', 'Semiurban'}\n"
     ]
    }
   ],
   "source": [
    "print(set(loan_train['Gender'].values.tolist()))\n",
    "print(set(loan_train['Dependents'].values.tolist()))\n",
    "print(set(loan_train['Married'].values.tolist()))\n",
    "print(set(loan_train['Education'].values.tolist()))\n",
    "print(set(loan_train['Self_Employed'].values.tolist()))\n",
    "print(set(loan_train['Loan_Status'].values.tolist()))\n",
    "print(set(loan_train['Property_Area'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8da9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "loan_train['Loan_Status'] = loan_train['Loan_Status'].map({'N': 0, 'Y': 1}).fillna(0).astype(int)\n",
    "loan_train = pd.get_dummies(loan_train, columns=['Gender', 'Dependents', 'Married', 'Education', 'Self Employed', 'Property_Area'])\n",
    "standardScaler = StandardScaler()\n",
    "loan_train['Loan_Term'] = loan_train['Loan_Amount_Term']\n",
    "del loan_train['Loan_Amount_Term']\n",
    "loan_train[['CoapplicantIncome', 'LoanAmount', 'Loan_Term']] = standardScaler.fit_transform(loan_train[['CoapplicantIncome', 'LoanAmount', 'Loan_Term']])\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e417129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "y = loan_train['Loan_Status']  # Select target variable (Loan_Status)\n",
    "X = loan_train.drop(['Loan_Status', 'Loan_ID'], axis=1)  # Drop target and ID columns\n",
    "\n",
    "# Split data using the defined variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d351eec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 31, 'max_depth': 1, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "Accuracy: 0.7886178861788617\n",
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "64 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "64 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1519, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.76386112 0.74553512 0.7373384  0.77197454 0.73947088 0.76181194\n",
      " 0.7597461         nan 0.7373384  0.7618286  0.75571438 0.75972944\n",
      " 0.74963348 0.74148674 0.78623551 0.73523924 0.76789284 0.78010462\n",
      " 0.77608956        nan 0.7435026  0.74351926        nan 0.77404038\n",
      " 0.77602292 0.75773024        nan 0.75981274 0.7415034  0.76792616\n",
      "        nan 0.76186192 0.78823471 0.76584366 0.76795948 0.76589364\n",
      " 0.75773024 0.76587698 0.75573104        nan        nan 0.74956684\n",
      " 0.76386112 0.76995868 0.74963348 0.7536652  0.74963348 0.74551846\n",
      " 0.74756764 0.7719912  0.7679095  0.75573104 0.75976276 0.73329002\n",
      " 0.74147008        nan 0.81467413 0.75161602 0.75773024 0.80654405\n",
      "        nan 0.75573104 0.74351926        nan 0.78416967 0.80246235\n",
      " 0.76179528 0.7597461  0.74960016 0.76789284 0.76587698 0.77197454\n",
      " 0.74753432 0.75573104        nan 0.7780721         nan 0.80451153\n",
      " 0.76586032        nan 0.75979608 0.7618286  0.76181194 0.75573104\n",
      " 0.74555178 0.7679095  0.75368186 0.76792616 0.75371518 0.74556844\n",
      " 0.77404038        nan        nan 0.74147008 0.78213715 0.74148674\n",
      " 0.78415301 0.74153672        nan 0.78010462]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gbm_param_grid = {\n",
    "    'n_estimators': range(1, 1000, 10),\n",
    "    'max_depth': range(1, 20),\n",
    "    'learning_rate': [.1, .4, .45, .5, .55, .6],\n",
    "    'colsample_bytree': [.6, .7, .8, .9, 1.0, 1.1]\n",
    "}\n",
    "X_train = pd.get_dummies(X_train, columns=['Self_Employed'])  # One-hot encode Self_Employed\n",
    "X_test = pd.get_dummies(X_test, columns=['Self_Employed'])\n",
    "xgb_classifier = XGBClassifier(enable_categorical=True)\n",
    "\n",
    "xgb_random = RandomizedSearchCV(param_distributions=gbm_param_grid,\n",
    "                                 estimator=xgb_classifier, scoring=\"accuracy\",\n",
    "                                 verbose=0, n_iter=100, cv=4)\n",
    "error_score='raise'\n",
    "\n",
    "\n",
    "xgb_random.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(f'Best parameters: {xgb_random.best_params_}')\n",
    "\n",
    "y_pred = xgb_random.predict(X_test)\n",
    "print(f'Accuracy: {np.sum(y_pred == y_test) / len(y_test)}')\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebbd18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 20, 'min_samples_split': 10}\n",
      "0.7804878048780488\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "\n",
    "'max_depth': range(4,25),\n",
    "'min_samples_leaf': range(10, 100, 10),\n",
    "'min_samples_split' : range(10, 100, 10),\n",
    "'criterion': ['gini', 'entropy']\n",
    "}\n",
    "n_folds = 5\n",
    "dt = DecisionTreeClassifier (random_state=np.random.randint(0, 100))\n",
    "dt_grid = GridSearchCV(dt, param_grid, cv = n_folds, return_train_score=True, verbose=0)\n",
    "dt_grid.fit(X_train,y_train)\n",
    "print(dt_grid.best_params_)\n",
    "# {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 20, 'min_samples_split': 10}\n",
    "y_pred_best=dt_grid.predict(X_test)\n",
    "acc = metrics.accuracy_score (y_test, y_pred_best)\n",
    "print(acc)\n",
    "# 0.7804878048780488\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85a2558d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 11, 'max_depth': 2, 'learning_rate': 0.45, 'colsample_bytree': 0.9}\n",
      "Accuracy: 0.7886178861788617\n",
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1519, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.77200786 0.7536652  0.74147008 0.76387778 0.74960016 0.75971278\n",
      " 0.75569772        nan 0.75569772        nan 0.7495835  0.79433227\n",
      " 0.76589364 0.76589364 0.76177862 0.76179528 0.75571438 0.7577469\n",
      " 0.74147008 0.75776356 0.75568106        nan 0.80857657 0.74555178\n",
      " 0.75571438 0.75369852 0.78823471 0.7374217  0.7577469  0.75168266\n",
      " 0.76587698 0.7679095  0.76997534        nan 0.76589364        nan\n",
      " 0.75573104 0.75776356 0.73337332 0.75773024 0.7577469         nan\n",
      " 0.75369852 0.74955018 0.74756764        nan 0.75769692 0.75569772\n",
      " 0.7556644  0.7699087  0.75979608 0.7597461  0.7536652  0.77400706\n",
      " 0.7597461  0.74965014 0.79026723 0.73947088 0.74555178 0.75364854\n",
      " 0.78010462 0.74351926 0.75979608 0.76587698 0.7597461  0.7577469\n",
      "        nan 0.74553512 0.76997534 0.7455851  0.7679095         nan\n",
      " 0.74963348 0.80244569 0.7577469         nan        nan 0.75773024\n",
      " 0.72929162        nan 0.75981274 0.74147008 0.77200786 0.7577469\n",
      " 0.75569772 0.74756764 0.74551846 0.80044649 0.7435026  0.76589364\n",
      " 0.74956684 0.75161602        nan        nan 0.76384446 0.75568106\n",
      " 0.75981274        nan 0.73943756 0.7536652 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gbm_param_grid = {\n",
    "    'n_estimators': range(1, 1000, 10),\n",
    "    'max_depth': range(1, 20),\n",
    "    'learning_rate': [.1, .4, .45, .5, .55, .6],\n",
    "    'colsample_bytree': [.6, .7, .8, .9, 1.0, 1.1]\n",
    "}\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "xgb_random = RandomizedSearchCV(param_distributions=gbm_param_grid,\n",
    "                                 estimator=xgb_classifier, scoring=\"accuracy\",\n",
    "                                 verbose=0, n_iter=100, cv=4)\n",
    "\n",
    "xgb_random.fit(X_train, y_train)\n",
    "print(f'Best parameters: {xgb_random.best_params_}')\n",
    "\n",
    "y_pred = xgb_random.predict(X_test)\n",
    "print(f'Accuracy: {np.sum(y_pred == y_test) / len(y_test)}')\n",
    "print('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming libraries are imported\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "svm_param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': range(1, 11)\n",
    "}\n",
    "\n",
    "# Create an SVC model\n",
    "svm = SVC()\n",
    "\n",
    "# Perform randomized search with cross-validation\n",
    "svm_random = RandomizedSearchCV(param_distributions=svm_param_grid,\n",
    "                                 estimator=svm, scoring=\"accuracy\",\n",
    "                                 verbose=0, n_iter=40, cv=4)\n",
    "\n",
    "# Train the model on your training data\n",
    "svm_random.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters found during tuning\n",
    "best_params = svm_random.best_params_\n",
    "print(f'Best parameters: {best_params}')\n",
    "\n",
    "# Predict on the test data using the best model\n",
    "y_pred_best = svm_random.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the test data\n",
    "acc = metrics.accuracy_score(y_test, y_pred_best)\n",
    "print(acc)\n",
    "\n",
    "# Print hello (assuming hello is defined elsewhere)\n",
    "print(\"hello\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_imp (df, model):\n",
    "    feat = pd.DataFrame(columns=['feature', 'importance'])\n",
    "    feat[\"feature\"] = df.columns\n",
    "    feat[\"importance\"] = model.best_estimator_.feature_importances_\n",
    "    return feat.sort_values(by=\" importance\", ascending=False)\n",
    "print('jello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ffb15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp(X_train, dt_grid).plot('feature', 'importance', 'barh',figsize=(10,7), legend=False)\n",
    "print('jello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
